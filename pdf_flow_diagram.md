# PDF RAG Demo Flow Diagram

## Complete Flow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PDF RAG DEMO INITIALIZATION                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Import Dependencies     â”‚
                    â”‚  Load LLM Model          â”‚
                    â”‚  (llama3.2:3b)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Vector DB Exists?        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                                  â”‚
                â–¼ YES                              â–¼ NO
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Load Existing DB â”‚         â”‚ Create New Database    â”‚
        â”‚ Check for new    â”‚         â”‚ (pdf_vector.py steps)  â”‚
        â”‚ PDFs & update    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
                â”‚                                  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Create Retriever             â”‚
                    â”‚ (similarity search, k=10)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER QUERY INPUT                             â”‚
â”‚       "How many players can play CATANIC RIDE TO HEAVEN?"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Choose Approach         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                                  â”‚
                â–¼                                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   WITHOUT RAG    â”‚        â”‚     WITH RAG         â”‚
        â”‚                  â”‚        â”‚                      â”‚
        â”‚ Direct LLM Query â”‚        â”‚ 1. Retrieve Docs     â”‚
        â”‚ (LLM only uses   â”‚        â”‚ 2. Build Context     â”‚
        â”‚  training data)  â”‚        â”‚ 3. LLM with Context  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                  â”‚
                â–¼                                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  LLM-Only Response   â”‚    â”‚   RAG-Enhanced Response  â”‚
        â”‚ (General knowledge   â”‚    â”‚   (Fact-based, accurate) â”‚
        â”‚  may be inaccurate)  â”‚    â”‚                          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Display Both Answers    â”‚
                    â”‚  for Comparison          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## STEP 1: PDF Vector Database Creation (pdf_vector.py)

### 1.1 Check if Vector DB Already Exists
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Does pdf_chroma_db/ exist?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
      YESâ”‚                    â”‚NO
         â”‚                    â”‚
         â–¼                    â–¼
    Load DB              Load PDFs from
    (from disk)          ./pdfs/ directory
         â”‚                    â”‚
         â”œâ”€ Check for    Extract pages
         â”‚  new PDFs     from each PDF
         â”‚                    â”‚
         â”‚              âœ“ Loads all PDF files
         â”‚              âœ“ Extracts text from pages
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
              âœ“ Faster (reuse existing data)
              âœ“ Auto-update with new PDFs
```

**Code:**
```python
# pdf_vector.py - Lines 88-121
if os.path.exists(persist_directory) and not force_rebuild:
    print(f"Loading existing vector DB from {persist_directory}")
    vectordb = Chroma(
        embedding_function=embeddings,
        persist_directory=persist_directory
    )
    existing_count = vectordb._collection.count()
    print(f"âœ“ Loaded existing DB with {existing_count} chunks")
    
    if auto_update:
        existing_sources = get_existing_sources(vectordb)
        current_pdfs = get_pdf_files(pdf_path)
        new_pdfs = [pdf for pdf in current_pdfs if pdf not in existing_sources]
        
        if new_pdfs:
            print(f"\nğŸ” Found {len(new_pdfs)} new PDF(s) to add")
```

---

### 1.2 Load PDF Files from Directory
```
./pdfs/ Directory
   â”‚
   â”œâ”€â–º file1.pdf
   â”œâ”€â–º file2.pdf
   â”œâ”€â–º file3.pdf
   â”‚
   â–¼
PyPDFLoader (for each PDF)
   â”‚
   â”œâ”€â–º Extract all pages
   â”œâ”€â–º Convert to Document objects
   â”‚
   â–¼
List of Documents
   â”‚
   â”œâ”€â–º Document 1: Page 1 of file1.pdf
   â”œâ”€â–º Document 2: Page 2 of file1.pdf
   â”œâ”€â–º Document 3: Page 1 of file2.pdf
   â”œâ”€â–º ... (all pages from all PDFs)
   â”‚
   â–¼
Total: N pages loaded
```

**Code:**
```python
# pdf_vector.py - Lines 18-29
def load_pdfs_from_directory(pdf_dir):
    loader = DirectoryLoader(
        pdf_dir,
        glob="**/*.pdf",
        loader_cls=PyPDFLoader
    )
    return loader.load()

# Called in main
documents = load_pdfs_from_directory(pdf_path)
print(f"âœ“ Loaded {len(documents)} pages from PDF(s)")
```

---

### 1.3 Chunk PDF Documents
```
PDF Page Content
   â”‚
   "Rules of Monopoly:
    1. Roll the dice...
    2. Move your piece...
    3. If you land on property..."
   â”‚
   â–¼
RecursiveCharacterTextSplitter
   â”‚
   â”œâ”€ Split at: \n\n (double newline)
   â”œâ”€ Then at: \n (newline)
   â”œâ”€ Then at: space
   â”œâ”€ Chunk size: 1000 characters
   â”œâ”€ Overlap: 200 characters (for context)
   â”‚
   â–¼
Multiple Chunks
   â”‚
   â”œâ”€â–º Chunk 1: "Rules of Monopoly: 1. Roll the dice..."
   â”œâ”€â–º Chunk 2: "2. Move your piece... [continues from chunk 1]"
   â”œâ”€â–º Chunk 3: "3. If you land on property..."
   â”‚
   â–¼
Chunked Documents (overlap ensures context)
```

**Code:**
```python
# pdf_vector.py - Lines 31-47
def chunk_documents(documents, chunk_size=1000, chunk_overlap=200):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        separators=["\n\n", "\n", " ", ""]
    )
    return text_splitter.split_documents(documents)

# Main
print(f"Chunking documents (size=1000, overlap=200)...")
chunked_docs = chunk_documents(documents)
print(f"âœ“ Created {len(chunked_docs)} chunks from {len(documents)} pages")
```

**Example:**
- 10 PDF pages â†’ 50 total chunks (with overlap for context)
- Each chunk: max 1000 characters
- Overlap: 200 characters between chunks

---

### 1.4 Initialize Embedding Model
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ollama Embedding Model         â”‚
â”‚ mxbai-embed-large:335m         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Ready to convert PDF chunks
    to 335-dimensional vectors
```

**Code:**
```python
# pdf_vector.py - Lines 141-142
embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)
print("âœ“ Embedding model initialized")
```

---

### 1.5 Generate Embeddings and Store in ChromaDB
```
Chunked Document 1: "Rules of Monopoly..."
   â”‚
   â–¼
Embedding Model
   â”‚
   â–¼
Vector: [0.234, -0.156, 0.890, ..., 0.123]  (335 dimensions)
   â”‚
   â”œâ”€â–º Store in ChromaDB
   â”œâ”€â–º Link to metadata (source PDF, page number)
   â””â”€â–º Save to disk (pdf_chroma_db/)

[Repeat for all chunks]
   â”‚
   â–¼
ChromaDB fully populated with vectors
Ready for similarity search
```

**Code:**
```python
# pdf_vector.py - Lines 144-150
vectordb = Chroma.from_documents(
    documents=chunked_docs,
    embedding=embeddings,
    persist_directory=persist_directory
)
print(f"âœ“ Vector DB created and saved to {persist_directory}")
print(f"  Total chunks embedded: {len(chunked_docs)}")
```

**Metadata Stored:**
```python
{
  "source": "/path/to/pdfs/board_games.pdf",
  "page": 2,
  "title": "Board Games Rules"
}
```

---

## STEP 2: Query Processing - Without RAG (pdf_main.py)

```
User Question
  â”‚
  "How many players can play 
   CATANIC RIDE TO HEAVEN?"
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Model (llama3.2:3b)          â”‚
â”‚ WITHOUT any PDF context          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º Uses only training data
  â”œâ”€â–º No access to actual PDFs
  â”œâ”€â–º May be wrong/made-up
  â””â”€â–º Cannot answer obscure games
  â”‚
  â–¼
"I don't have information about 
CATANIC RIDE TO HEAVEN in my 
training data. It may not be 
a real board game."
(Inaccurate!)
```

**Code:**
```python
# pdf_main.py - Lines 18-22
def ask_without_rag(question: str) -> str:
    """Ask the LLM directly without vector database context."""
    prompt = f"You are a board games expert. Answer the following question:\n\nQuestion: {question}\n\nAnswer:"
    return model.invoke(prompt)
```

---

## STEP 3: Query Processing - With RAG (pdf_main.py)

### 3.1 Retrieve Relevant Document Chunks from PDF Vector Database
```
User Question
  â”‚
  "How many players can play 
   CATANIC RIDE TO HEAVEN?"
  â”‚
  â–¼
Convert to Embedding
(same model: mxbai-embed-large:335m)
  â”‚
  â–¼
Vector: [0.145, -0.234, 0.567, ..., 0.890]
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChromaDB Similarity Search        â”‚
â”‚ Find top 10 most similar chunks  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”œâ”€â–º Chunk 1: "CATANIC RIDE TO HEAVEN rules page 1..." - Similarity: 0.98
  â”œâ”€â–º Chunk 2: "Player count: 2-6 players per game..." - Similarity: 0.95
  â”œâ”€â–º Chunk 3: "Setup instructions for this game..." - Similarity: 0.89
  â”œâ”€â–º ... (more chunks)
  â”‚
  â–¼
Return top 10 chunks with metadata
   (source file, page number, exact text)
```

**Code:**
```python
# pdf_main.py - Lines 36-37
def ask_with_rag(question: str) -> str:
    retrieved_docs = retriever_pdf.invoke(question)
```

---

### 3.2 Build Context Prompt with Retrieved PDF Chunks
```
Retrieved Chunks (10 board game rules)
  â”‚
  â”œâ”€â–º Chunk 1: Rules details
  â”œâ”€â–º Chunk 2: Player count info
  â”œâ”€â–º Chunk 3: More rules
  â”œâ”€â–º ... (more chunks with actual PDF content)
  â”‚
  â–¼
Format into prompt:
  â”‚
  "You are a board games expert.
   
   Here are the relevant info:
   
   === Board Game 1 ===
   CATANIC RIDE TO HEAVEN
   Rules: Players compete to reach heaven...
   Player Count: 2-6 players
   Setup: Each player gets...
   
   === Board Game 2 ===
   [More rules from PDFs...]
   
   Question: How many players can play CATANIC RIDE TO HEAVEN?
   
   Provide a clear answer based on the board games data above:"
  â”‚
  â–¼
Full context-rich prompt ready for LLM
```

**Code:**
```python
# pdf_main.py - Lines 40-46
prompt = f"You are a board games expert. Answer the following question based on the data provided.\n\n"
prompt += f"Here are the relevant info:\n\n"

for i, doc in enumerate(retrieved_docs, 1):
    prompt += f"=== Board Game {i} ===\n{doc.page_content}\n\n"

prompt += f"Question: {question}\n\nProvide a clear answer based on the board games data above:"
```

---

### 3.3 Generate RAG-Enhanced Answer
```
LLM Model (with PDF context)
  â”‚
  â”œâ”€â–º Sees actual PDF content
  â”œâ”€â–º Can reference real rules
  â”œâ”€â–º Provides accurate information
  â””â”€â–º Backed by source documents
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG-ENHANCED RESPONSE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  "Based on the board games data provided:
  
  CATANIC RIDE TO HEAVEN can be played with 
  2 to 6 players. The game supports both 
  competitive and cooperative play modes."
  â”‚
  â–¼
(Accurate! Verifiable from PDF!)
```

---

## STEP 4: PDF Processing Pipeline Detailed View

### Data Transformation Pipeline
```
PDF Files in ./pdfs/
   â”‚
   â”œâ”€â–º board_game_1.pdf
   â”œâ”€â–º board_game_2.pdf
   â”œâ”€â–º board_game_3.pdf
   â”‚
   â–¼
Step 1: Load PDFs
   â”‚
   â”œâ”€â–º Extract all pages
   â”œâ”€â–º 30 total pages
   â”‚
   â–¼
Step 2: Chunk Documents
   â”‚
   â”œâ”€â–º 1000 char chunks with 200 char overlap
   â”œâ”€â–º 85 total chunks
   â”‚
   â–¼
Step 3: Generate Embeddings
   â”‚
   â”œâ”€â–º Convert each chunk to vector (335 dimensions)
   â”œâ”€â–º 85 vectors created
   â”‚
   â–¼
Step 4: Store in ChromaDB
   â”‚
   â”œâ”€â–º Save to pdf_chroma_db/
   â”œâ”€â–º Ready for queries
   â”‚
   â–¼
NEXT TIME: Load from disk (< 1 second)
```

---

## Configuration

```yaml
PDF Processing:
  Source directory: ./pdfs/
  File pattern: **/*.pdf (recursive)
  PDF Loader: PyPDFLoader
  
Chunking Strategy:
  Chunk size: 1000 characters
  Overlap: 200 characters
  Split at: Double newline, newline, space, character
  
Embedding:
  Model: mxbai-embed-large:335m
  Dimensions: 335 million parameters
  Size: ~335MB
  
LLM:
  Model: llama3.2:3b
  Size: ~2GB
  
Vector Database:
  Type: ChromaDB
  Backend: SQLite
  Location: pdf_chroma_db/
  Retrieval: Similarity search (cosine distance)
  
Query Parameters:
  Top K results: 10 chunks
  Search type: similarity
  
Auto-Update:
  Enabled: YES
  New PDFs added automatically
  Existing data preserved
```

---

## Running the PDF Demo

```bash
# Step 1: Create/update vector database from PDFs
python pdf_vector.py

# Step 2: Run the comparison demo
python pdf_main.py
```

**Expected Output:**
```
WITHOUT RAG (Using LLM Knowledge Only)
================================================================================
[LLM-only response - may be generic or wrong]

================================================================================
WITH RAG (Using PDFs Content)
================================================================================
[RAG-enhanced response - accurate, from PDF rules]
```

---

## Key Differences: PDF vs CSV Data

| Aspect | CSV Data | PDF Data |
|--------|----------|----------|
| **Source** | Structured records | Unstructured text |
| **Processing** | One record per doc | Pages chunked into overlapping pieces |
| **Chunking** | Not needed | Required (chunk_size=1000) |
| **Documents** | 500 books | Hundreds/thousands of chunks |
| **Context** | Metadata preserved | Page numbers & source file |
| **Auto-update** | Check for new files | Add new PDFs automatically |
| **Storage** | Simpler | More complex (chunks with overlap) |

---

## Troubleshooting

### "No PDFs found in directory"
- Verify PDFs are in `./pdfs/` folder
- Check file permissions
- Ensure `.pdf` extension (lowercase)

### "PDF parsing errors"
- Check if PDFs are password-protected
- Try opening PDF in your system first
- Some PDFs may have encoding issues

### "Chunking creates too many/too few chunks"
- Adjust `CHUNK_SIZE` (current: 1000)
- Adjust `CHUNK_OVERLAP` (current: 200)
- Larger chunks = fewer total chunks
- More overlap = more context but slower search
